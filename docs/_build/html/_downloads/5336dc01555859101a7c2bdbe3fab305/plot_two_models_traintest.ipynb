{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Regression: comparing two tabular models trained on simulated data\n\nThis script shows how to train two fusion models on a regression task with train/test protocol and multimodal tabular data.\n\nKey Features:\n\n- Importing models based on name.\n- Training and testing models with train/test protocol.\n- Saving trained models to a dictionary for later analysis.\n- Plotting the results of a single model.\n- Plotting the results of multiple models as a bar chart.\n- Saving the results of multiple models as a csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import importlib\n\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\n\nfrom docs.examples import generate_sklearn_simulated_data\nfrom fusionlibrary.datamodules import get_data_module\nfrom fusionlibrary.eval_functions import Plotter\nfrom fusionlibrary.fusion_models.base_pl_model import BaseModel\nfrom fusionlibrary.train_functions import train_and_save_models\nfrom fusionlibrary.utils.model_chooser import get_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import fusion models\nHere we import the fusion models to be compared. The models are imported using the\n:func:`~fusionlibrary.utils.model_chooser.get_models` function, which takes a dictionary of conditions\nas an input. The conditions are the attributes of the models, e.g. the class name, the modality type, etc.\n\nThe function returns a dataframe of the models that match the conditions. The dataframe contains the\nmethod name, the class name, the modality type, the fusion type, the path to the model, and the path to the\nmodel's parent class. The paths are used to import the models with the :func:`importlib.import_module`.\n\nWe're importing ConcatTabularData and TabularChannelWiseMultiAttention models for this example. Both are multimodal tabular models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_conditions = {\n    \"class_name\": [\"ConcatTabularData\", \"TabularChannelWiseMultiAttention\"],\n}\n\nimported_models = get_models(model_conditions)\nprint(\"Imported methods:\")\nprint(imported_models.method_name.values)\n\nfusion_models = []  # contains the class objects for each model\nfor index, row in imported_models.iterrows():\n    module = importlib.import_module(row[\"method_path\"])\n    module_class = getattr(module, row[\"class_name\"])\n\n    fusion_models.append(module_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Set the training parameters\nHere we define the parameters for training and testing the models. The parameters are stored in a dictionary and passed to most\nof the methods in this library.\nFor training and testing, the necessary parameters are:\n\n- ``test_size``: the proportion of the data to be used for testing.\n- ``kfold_flag``: the user sets this to False for train/test protocol.\n- ``log``: a boolean of whether to log the results using Weights and Biases.\n- ``pred_type``: the type of prediction to be performed. This is either ``regression``, ``binary``, or ``classification``. For this example we're using regression.\n\nIf we were going to use a subspace-based fusion model, we would also need to set the latent dimensionality of the subspace with ``subspace_latdims``. This will be shown in a different example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = {\n    \"test_size\": 0.2,\n    \"kfold_flag\": False,\n    \"log\": False,\n    \"pred_type\": \"regression\",\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Generating simulated data\nHere we generate simulated data for the two tabular modalities for this example.\nThis function also simulated image data which we aren't using here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params = generate_sklearn_simulated_data(\n    num_samples=500,\n    num_tab1_features=10,\n    num_tab2_features=10,\n    img_dims=(1, 100, 100),\n    params=params,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training the first fusion model\nHere we train the first fusion model. We're using the ``train_and_save_models`` function to train and test the models.\nThis function takes the following inputs:\n\n- ``trained_models_dict``: a dictionary to store the trained models.\n- ``data_module``: the data module containing the data.\n- ``params``: the parameters for training and testing.\n- ``fusion_model``: the fusion model to be trained.\n- ``init_model``: the initialised dummy fusion model.\n\nFirst we'll create a dictionary to store both the trained models so we can compare them later.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "all_trained_models = {}  # create dictionary to store trained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To train the first model we need to:\n\n1. *Choose the model*: We're using the first model in the ``fusion_models`` list we made earlier.\n2. *Create a dictionary to store the trained model*: We're using the name of the model as the key. It may seem overkill to make a dictionary just to store one model, but we also use this when we do k-fold training to store the trained models from the different folds.\n3. *Initialise the model with dummy data*: This is so we can find out whether there are extra instructions for creating the datamodule (such as a method for creating a graph datamodule).\n4. *Print the attributes of the model*: To check it's been initialised correctly.\n5. *Create the datamodule*: This is done with the :func:`~fusionlibrary.datamodules.get_data_module` function. This function takes the initialised model and the parameters as inputs. It returns the datamodule.\n6. *Train and test the model*: This is done with the :func:`~fusionlibrary.train_functions.train_and_save_models` function. This function takes the trained_models_dict, the datamodule, the parameters, the fusion model, and the initialised model as inputs. It returns the trained_models_dict with the trained model added to it.\n7. *Add the trained model to the ``all_trained_models`` dictionary*: This is so we can compare the results of the two models later.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fusion_model = fusion_models[0]\n\nprint(\"Method name:\", fusion_model.method_name)\nprint(\"Modality type:\", fusion_model.modality_type)\nprint(\"Fusion type:\", fusion_model.fusion_type)\n\n# Create the data module\ndm = get_data_module(fusion_model=fusion_model, params=params)\n\n# Train and test\nmodel_1_dict = train_and_save_models(\n    data_module=dm,\n    params=params,\n    fusion_model=fusion_model,\n)\n\n# Add trained model to dictionary\nall_trained_models[fusion_model.__name__] = model_1_dict[fusion_model.__name__]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Plotting the results of the first model\nWe're using the :class:`~fusionlibrary.eval_functions.Plotter` class to plot the results of the first model. This class takes the dictionary of trained models and the parameters as inputs. It returns a dictionary of figures.\nIf there is one model in the dictionary (i.e. only one unique key), then it plots the figures for analysing the results of a single model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotter = Plotter(model_1_dict, params)\nsingle_model_figures_dict = plotter.plot_all()\nplotter.show_all(single_model_figures_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training the second fusion model\nHere we train the second fusion model: TabularChannelWiseMultiAttention. We're using the same steps as before, but this time we're using the second model in the ``fusion_models`` list.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Choose the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fusion_model = fusion_models[1]\n\n\nprint(\"Method name:\", fusion_model.method_name)\nprint(\"Modality type:\", fusion_model.modality_type)\nprint(\"Fusion type:\", fusion_model.fusion_type)\n\n# Create the data module\ndm = get_data_module(fusion_model=fusion_model, params=params)\n\n# Train and test\nmodel_2_dict = train_and_save_models(\n    data_module=dm,\n    params=params,\n    fusion_model=fusion_model,\n)\n\n# Add trained model to dictionary\nall_trained_models[fusion_model.__name__] = model_2_dict[fusion_model.__name__]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Plotting the results of the second model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotter = Plotter(model_2_dict, params)\nsingle_model_figures_dict = plotter.plot_all()\nplotter.show_all(single_model_figures_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Comparing the results of the two models\nNow we're going to compare the results of the two models. We're using the same steps as when we used Plotter before, but this time we're using the ``all_trained_models`` dictionary which contains both models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "comparison_plotter = Plotter(all_trained_models, params)\ncomparison_plot_dict = comparison_plotter.plot_all()\ncomparison_plotter.show_all(comparison_plot_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Saving the metrics of the two models\nWe can also get the metrics of the two models into a Pandas DataFrame using the :func:`~fusionlibrary.eval_functions.Plotter.get_performance_df` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "performances_df = comparison_plotter.get_performance_df()\nperformances_df"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}