<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>How to modify architectures of fusion models &mdash; fusilli  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/fonts.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/florencestheme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/pink_pasta_logo.png"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Adding a new model" href="../../contributing_examples/index.html" />
    <link rel="prev" title="How to use Weights and Biases Logging with Fusilli" href="how_to_use_logging.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            fusilli
              <img src="../../_static/pink_pasta_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">üå∏ Table of Contents üå∏</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html"><strong>fusilli</strong>: an introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../user_guide.html">User guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fusion_model_explanations.html">Fusion Model Explanations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modifying_models.html">Modifying the fusion models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üå∏ Tutorials üå∏</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../training_and_testing/index.html">Training and testing</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Customising behaviour</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="how_to_use_logging.html">How to use Weights and Biases Logging with Fusilli</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">How to modify architectures of fusion models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#setting-up-the-experiment">Setting up the experiment</a></li>
<li class="toctree-l3"><a class="reference internal" href="#specifying-the-model-modifications">Specifying the model modifications</a></li>
<li class="toctree-l3"><a class="reference internal" href="#loading-the-data-and-training-the-model">Loading the data and training the model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#what-happens-when-the-modifications-are-incorrect">What happens when the modifications are incorrect?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üå∏ How to contribute üå∏</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contributing_examples/index.html">Adding a new model</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">üå∏ API Reference üå∏</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../autosummary/fusilli.fusionmodels.html">fusilli.fusionmodels</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autosummary/fusilli.data.html">fusilli.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autosummary/fusilli.train.html">fusilli.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autosummary/fusilli.eval.html">fusilli.eval</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../autosummary/fusilli.utils.html">fusilli.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">fusilli</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Customising behaviour</a></li>
      <li class="breadcrumb-item active">How to modify architectures of fusion models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/auto_examples/customising_behaviour/plot_modify_layer_sizes.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-customising-behaviour-plot-modify-layer-sizes-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="how-to-modify-architectures-of-fusion-models">
<span id="sphx-glr-auto-examples-customising-behaviour-plot-modify-layer-sizes-py"></span><h1>How to modify architectures of fusion models<a class="headerlink" href="#how-to-modify-architectures-of-fusion-models" title="Permalink to this heading">ÔÉÅ</a></h1>
<p>This tutorial will show you how to modify the architectures of fusion models.</p>
<p>More guidance on what can be modified in each fusion model can be found in the <a class="reference internal" href="../../modifying_models.html#modifying-models"><span class="std std-ref">Modifying the fusion models</span></a> section.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Some of the fusion models have been designed to work with specific architectures and there are some restrictions on how they can be modified.</p>
<p>For example, the channel-wise attention model requires the two modalities to have the same number of layers. Please read the notes section of the fusion model you are interested in to see if there are any restrictions.</p>
</div>
<section id="setting-up-the-experiment">
<h2>Setting up the experiment<a class="headerlink" href="#setting-up-the-experiment" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>First, we will set up the experiment by importing the necessary packages, creating the simulated data, and setting the parameters for the experiment.</p>
<p>For a more detailed explanation of this process, please see the <a class="reference internal" href="../../examples/training_and_testing/README.html#train-test-examples"><span class="std std-ref">Training and testing</span></a> tutorials.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">from</span> <span class="nn">docs.examples</span> <span class="kn">import</span> <span class="n">generate_sklearn_simulated_data</span>
<span class="kn">from</span> <span class="nn">fusilli.data</span> <span class="kn">import</span> <span class="n">get_data_module</span>
<span class="kn">from</span> <span class="nn">fusilli.eval</span> <span class="kn">import</span> <span class="n">RealsVsPreds</span>
<span class="kn">from</span> <span class="nn">fusilli.train</span> <span class="kn">import</span> <span class="n">train_and_save_models</span>

<span class="kn">from</span> <span class="nn">fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps</span> <span class="kn">import</span> <span class="n">DAETabImgMaps</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;test_size&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="s2">&quot;kfold_flag&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;log&quot;</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s2">&quot;pred_type&quot;</span><span class="p">:</span> <span class="s2">&quot;regression&quot;</span><span class="p">,</span>
    <span class="s2">&quot;loss_log_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;loss_logs&quot;</span><span class="p">,</span>  <span class="c1"># where the csv of the loss is saved for plotting later</span>
    <span class="s2">&quot;checkpoint_dir&quot;</span><span class="p">:</span> <span class="s2">&quot;checkpoints&quot;</span><span class="p">,</span>
    <span class="s2">&quot;loss_fig_path&quot;</span><span class="p">:</span> <span class="s2">&quot;loss_figures&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">generate_sklearn_simulated_data</span><span class="p">(</span>
    <span class="n">num_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">num_tab1_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">num_tab2_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">img_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
    <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="specifying-the-model-modifications">
<h2>Specifying the model modifications<a class="headerlink" href="#specifying-the-model-modifications" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>Now, we will specify the modifications we want to make to the model.</p>
<p>We are using the <a class="reference internal" href="../../autosummary/fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.html#fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.DAETabImgMaps" title="fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.DAETabImgMaps"><code class="xref py py-class docutils literal notranslate"><span class="pre">DAETabImgMaps</span></code></a> model for this example.
This is a subspace-based model which has two PyTorch models that need to be pretrained (a denoising autoencoder for the tabular modality, and a convolutional neural network for the image modality).
The fusion model then uses the latent representations of these models to perform the fusion.</p>
<p>The following modifications can be made to the <strong>pre-trained subspace</strong> model <a class="reference internal" href="../../autosummary/fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.html#fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.denoising_autoencoder_subspace_method" title="fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.denoising_autoencoder_subspace_method"><code class="xref py py-class docutils literal notranslate"><span class="pre">denoising_autoencoder_subspace_method</span></code></a>:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 40%" />
<col style="width: 60%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Guidance</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">autoencoder.latent_dim</span></code></p></td>
<td><p>int</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">autoencoder.upsampler</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">autoencoder.downsampler</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">img_unimodal.img_layers</span></code></p></td>
<td><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></li>
<li><p>Overrides modification of <code class="docutils literal notranslate"><span class="pre">img_layers</span></code> made to ‚Äúall‚Äù</p></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">img_unimodal.fused_layers</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></td>
</tr>
</tbody>
</table>
<p>The following modifications can be made to the <strong>fusion</strong> model <a class="reference internal" href="../../autosummary/fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.html#fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.DAETabImgMaps" title="fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.DAETabImgMaps"><code class="xref py py-class docutils literal notranslate"><span class="pre">DAETabImgMaps</span></code></a>:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 40%" />
<col style="width: 60%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Attribute</p></th>
<th class="head"><p>Guidance</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="../../autosummary/fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.html#fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.DAETabImgMaps.fusion_layers" title="fusilli.fusionmodels.tabularimagefusion.denoise_tab_img_maps.DAETabImgMaps.fusion_layers"><code class="xref py py-attr docutils literal notranslate"><span class="pre">fusion_layers</span></code></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></td>
</tr>
</tbody>
</table>
<p>Let‚Äôs change everything that we can!</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">layer_mods</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;DAETabImgMaps&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;fusion_layers&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">420</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">420</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">78</span><span class="p">),</span>
        <span class="p">),</span>
    <span class="p">},</span>
    <span class="s2">&quot;denoising_autoencoder_subspace_method&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;autoencoder.latent_dim&quot;</span><span class="p">:</span> <span class="mi">150</span><span class="p">,</span>  <span class="c1"># denoising autoencoder latent dim</span>
        <span class="s2">&quot;autoencoder.upsampler&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="p">),</span>
        <span class="s2">&quot;autoencoder.downsampler&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">80</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="p">),</span>
        <span class="s2">&quot;img_unimodal.img_layers&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">&quot;layer 1&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
                <span class="p">),</span>
                <span class="s2">&quot;layer 2&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
                <span class="p">),</span>
                <span class="s2">&quot;layer 3&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">60</span><span class="p">,</span> <span class="mi">85</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                    <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
                <span class="p">),</span>
            <span class="p">}</span>
        <span class="p">),</span>
        <span class="s2">&quot;img_unimodal.fused_layers&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">85</span><span class="p">,</span> <span class="mi">150</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">75</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">75</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="p">),</span>
    <span class="p">},</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="loading-the-data-and-training-the-model">
<h2>Loading the data and training the model<a class="headerlink" href="#loading-the-data-and-training-the-model" title="Permalink to this heading">ÔÉÅ</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># load data</span>
<span class="n">datamodule</span> <span class="o">=</span> <span class="n">get_data_module</span><span class="p">(</span><span class="n">DAETabImgMaps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">layer_mods</span><span class="o">=</span><span class="n">layer_mods</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>

<span class="c1"># train</span>
<span class="n">trained_models_dict</span> <span class="o">=</span> <span class="n">train_and_save_models</span><span class="p">(</span>
    <span class="n">data_module</span><span class="o">=</span><span class="n">datamodule</span><span class="p">,</span>
    <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">,</span>
    <span class="n">fusion_model</span><span class="o">=</span><span class="n">DAETabImgMaps</span><span class="p">,</span>
    <span class="n">layer_mods</span><span class="o">=</span><span class="n">layer_mods</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Changed latent_dim in denoising_autoencoder_subspace_method
Changed upsampler in denoising_autoencoder_subspace_method
Changed downsampler in denoising_autoencoder_subspace_method
Changed img_layers in denoising_autoencoder_subspace_method
Changed fused_layers in denoising_autoencoder_subspace_method
Reset fused layers in denoising_autoencoder_subspace_method
Reset fused layers in denoising_autoencoder_subspace_method

Training: |          | 0/? [00:00&lt;?, ?it/s]
Training:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 39.13it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 38.83it/s]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 73.06it/s]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 72.80it/s]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 103.34it/s]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 103.00it/s]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 131.84it/s]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 131.44it/s]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 157.64it/s]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 157.22it/s]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 181.42it/s]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 180.97it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 204.40it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 203.93it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 181.32it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 180.36it/s]
Epoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 1:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 604.98it/s]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 565.96it/s]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 618.63it/s]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 597.95it/s]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 639.83it/s]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 624.62it/s]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 648.22it/s]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 636.95it/s]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 653.60it/s]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 645.58it/s]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 656.04it/s]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 649.64it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 665.10it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 655.68it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 511.02it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 504.51it/s]
Epoch 1:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 2:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 515.46it/s]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 482.88it/s]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 545.28it/s]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 527.32it/s]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 575.38it/s]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 563.93it/s]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 601.33it/s]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 590.58it/s]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 609.25it/s]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 602.56it/s]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 629.27it/s]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 622.35it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 640.21it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 634.92it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 501.11it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 494.42it/s]
Epoch 2:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 3:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 580.45it/s]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 546.49it/s]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 637.58it/s]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 614.46it/s]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 640.65it/s]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 625.14it/s]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 635.96it/s]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 626.97it/s]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 656.53it/s]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 647.59it/s]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 664.83it/s]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 657.76it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 679.81it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 673.01it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 522.67it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 515.24it/s]
Epoch 3:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 4:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 663.24it/s]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 624.62it/s]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 689.40it/s]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 664.29it/s]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 678.29it/s]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 663.87it/s]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 689.91it/s]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 677.40it/s]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 696.10it/s]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 687.39it/s]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 698.64it/s]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 687.76it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 688.38it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 681.00it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 526.17it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 518.14it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 443.63it/s]

Training: |          | 0/? [00:00&lt;?, ?it/s]
Training:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:02,  2.43it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:02,  2.43it/s]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  2.76it/s]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  2.76it/s]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01&lt;00:01,  2.89it/s]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:01&lt;00:01,  2.89it/s]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:01,  2.98it/s]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:01,  2.98it/s]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.03it/s]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.03it/s]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.07it/s]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.07it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.43it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.43it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.18it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.18it/s]
Epoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 1:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.20it/s]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.20it/s]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.22it/s]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.22it/s]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.23it/s]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.23it/s]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.24it/s]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.24it/s]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.25it/s]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.25it/s]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.26it/s]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.26it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01&lt;00:00,  3.64it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01&lt;00:00,  3.64it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.38it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.38it/s]
Epoch 1:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 2:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.27it/s]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.27it/s]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.30it/s]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.30it/s]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.29it/s]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.29it/s]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.30it/s]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.30it/s]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.30it/s]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.30it/s]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.31it/s]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.31it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01&lt;00:00,  3.69it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01&lt;00:00,  3.69it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.42it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.42it/s]
Epoch 2:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 3:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.34it/s]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.34it/s]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.32it/s]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.32it/s]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.29it/s]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.29it/s]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.30it/s]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.30it/s]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.31it/s]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.31it/s]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.31it/s]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.31it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01&lt;00:00,  3.68it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01&lt;00:00,  3.68it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.41it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.41it/s]
Epoch 3:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 4:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.32it/s]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.32it/s]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.31it/s]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.31it/s]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.30it/s]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.30it/s]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.30it/s]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.30it/s]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.30it/s]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.30it/s]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.29it/s]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.29it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01&lt;00:00,  3.67it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:01&lt;00:00,  3.67it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.40it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.40it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.38it/s]
Changed fusion_layers in DAETabImgMaps
Reset fused layers in DAETabImgMaps
/Users/florencetownend/miniforge3/envs/fusion_eval/lib/python3.9/site-packages/lightning/fabric/loggers/csv_logs.py:196: Experiment logs directory loss_logs/DAETabImgMaps exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!

Training: |          | 0/? [00:00&lt;?, ?it/s]
Training:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 20.75it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 20.65it/s, v_num=Maps]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 24.23it/s, v_num=Maps]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 24.18it/s, v_num=Maps]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 25.65it/s, v_num=Maps]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 25.61it/s, v_num=Maps]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 26.84it/s, v_num=Maps]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 26.81it/s, v_num=Maps]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 27.53it/s, v_num=Maps]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 27.51it/s, v_num=Maps]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 28.01it/s, v_num=Maps]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 27.99it/s, v_num=Maps]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 29.02it/s, v_num=Maps]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 29.00it/s, v_num=Maps]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 26.47it/s, v_num=Maps, val_loss=24.80]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 26.43it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:   0%|          | 0/7 [00:00&lt;?, ?it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 28.48it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 28.33it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 29.87it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 29.78it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 30.01it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 29.96it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 30.19it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 30.15it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 30.26it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 30.23it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 30.38it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 30.36it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 31.10it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 31.08it/s, v_num=Maps, val_loss=24.80, train_loss=36.30]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 28.33it/s, v_num=Maps, val_loss=24.20, train_loss=36.30]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 28.28it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 1:   0%|          | 0/7 [00:00&lt;?, ?it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:   0%|          | 0/7 [00:00&lt;?, ?it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 22.92it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 22.82it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 26.64it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 26.58it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 28.06it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 28.01it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 28.90it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 28.87it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 29.50it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 29.47it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 29.80it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 29.78it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 30.50it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 30.47it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 27.92it/s, v_num=Maps, val_loss=24.20, train_loss=34.50]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 27.87it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 2:   0%|          | 0/7 [00:00&lt;?, ?it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:   0%|          | 0/7 [00:00&lt;?, ?it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 28.25it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 28.11it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 30.01it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 29.92it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 30.41it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 30.35it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 30.60it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 30.56it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 30.78it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 30.75it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 30.96it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 30.93it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 31.75it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 31.72it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 29.02it/s, v_num=Maps, val_loss=24.20, train_loss=33.70]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 28.98it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 3:   0%|          | 0/7 [00:00&lt;?, ?it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:   0%|          | 0/7 [00:00&lt;?, ?it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 29.31it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 29.15it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 30.36it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 30.28it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 30.87it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 30.82it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 31.20it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 31.15it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 31.30it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 31.27it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 31.18it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 31.15it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 31.89it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 31.86it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 29.09it/s, v_num=Maps, val_loss=24.20, train_loss=31.70]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 29.05it/s, v_num=Maps, val_loss=24.20, train_loss=33.40]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 18.15it/s, v_num=Maps, val_loss=24.20, train_loss=33.40]
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ      Validate metric      ‚îÉ       DataLoader 0        ‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ          MAE_val          ‚îÇ     4.019133567810059     ‚îÇ
‚îÇ          R2_val           ‚îÇ  -0.00010371208190917969  ‚îÇ
‚îÇ         val_loss          ‚îÇ    24.194211959838867     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
</pre></div>
</div>
<p>It worked! Let‚Äôs have a look at the model structure to see what changes have been made.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Subspace Denoising Autoencoder:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">subspace_method_train</span><span class="o">.</span><span class="n">autoencoder</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Subspace Image CNN:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">datamodule</span><span class="o">.</span><span class="n">subspace_method_train</span><span class="o">.</span><span class="n">img_unimodal</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fusion model:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">trained_models_dict</span><span class="p">[</span><span class="s2">&quot;DAETabImgMaps&quot;</span><span class="p">])</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Subspace Denoising Autoencoder:
 DenoisingAutoencoder(
  (upsampler): Sequential(
    (0): Linear(in_features=10, out_features=80, bias=True)
    (1): ReLU()
    (2): Linear(in_features=80, out_features=100, bias=True)
    (3): ReLU()
    (4): Linear(in_features=100, out_features=150, bias=True)
    (5): ReLU()
  )
  (downsampler): Sequential(
    (0): Linear(in_features=150, out_features=100, bias=True)
    (1): ReLU()
    (2): Linear(in_features=100, out_features=80, bias=True)
    (3): ReLU()
    (4): Linear(in_features=80, out_features=10, bias=True)
    (5): ReLU()
  )
  (loss): MSELoss()
)
Subspace Image CNN:
 ImgUnimodalDAE(
  (img_layers): ModuleDict(
    (layer 1): Sequential(
      (0): Conv2d(1, 40, kernel_size=(3, 3), stride=(1, 1))
      (1): ReLU()
      (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
    )
    (layer 2): Sequential(
      (0): Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1))
      (1): ReLU()
      (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
    )
    (layer 3): Sequential(
      (0): Conv2d(60, 85, kernel_size=(3, 3), stride=(1, 1))
      (1): ReLU()
      (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
    )
  )
  (fused_layers): Sequential(
    (0): Linear(in_features=8500, out_features=150, bias=True)
    (1): ReLU()
    (2): Linear(in_features=150, out_features=75, bias=True)
    (3): ReLU()
    (4): Linear(in_features=75, out_features=50, bias=True)
    (5): ReLU()
  )
  (final_prediction): Sequential(
    (0): Linear(in_features=50, out_features=1, bias=True)
  )
)
Fusion model:
 [BaseModel(
  (model): DAETabImgMaps(
    (fusion_layers): Sequential(
      (0): Linear(in_features=40390, out_features=420, bias=True)
      (1): ReLU()
      (2): Linear(in_features=420, out_features=100, bias=True)
      (3): ReLU()
      (4): Linear(in_features=100, out_features=78, bias=True)
    )
    (final_prediction): Sequential(
      (0): Linear(in_features=78, out_features=1, bias=True)
    )
  )
)]
</pre></div>
</div>
</section>
<section id="what-happens-when-the-modifications-are-incorrect">
<h2>What happens when the modifications are incorrect?<a class="headerlink" href="#what-happens-when-the-modifications-are-incorrect" title="Permalink to this heading">ÔÉÅ</a></h2>
<p>Let‚Äôs see what happens when we try to modify an <strong>attribute that doesn‚Äôt exist</strong>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">layer_mods</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;denoising_autoencoder_subspace_method&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;autoencoder.fake_layers&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">420</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">420</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">78</span><span class="p">),</span>
        <span class="p">),</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">datamodule</span> <span class="o">=</span> <span class="n">get_data_module</span><span class="p">(</span><span class="n">DAETabImgMaps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">layer_mods</span><span class="o">=</span><span class="n">layer_mods</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Layer group autoencoder.fake_layers not found in denoising_autoencoder_subspace_method
</pre></div>
</div>
<p>What about modifying an attribute with the <strong>wrong data type</strong>?</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">latent_dim</span></code> should be an <code class="docutils literal notranslate"><span class="pre">int</span></code> and greater than 0.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">upsampler</span></code> should be an <code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">downsampler</span></code> should be an <code class="docutils literal notranslate"><span class="pre">nn.Sequential</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">img_layers</span></code> should be an <code class="docutils literal notranslate"><span class="pre">nn.ModuleDict</span></code></p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">layer_mods</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;denoising_autoencoder_subspace_method&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;autoencoder.latent_dim&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">get_data_module</span><span class="p">(</span><span class="n">DAETabImgMaps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">layer_mods</span><span class="o">=</span><span class="n">layer_mods</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Changed latent_dim in denoising_autoencoder_subspace_method
(&#39;The latent dimension must be greater than 0. The latent dimension is currently: &#39;, 0)
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">layer_mods</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;denoising_autoencoder_subspace_method&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;autoencoder.upsampler&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">get_data_module</span><span class="p">(</span><span class="n">DAETabImgMaps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">layer_mods</span><span class="o">=</span><span class="n">layer_mods</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Changed upsampler in denoising_autoencoder_subspace_method
(&#39;Incorrect data type for the modifications: Attribute upsampler must be of type Sequential, not dtype Linear.&#39;,)
</pre></div>
</div>
<p>What about modifying multiple attributes with the <strong>conflicting modifications</strong>?</p>
<p>For this, let‚Äôs modify the <code class="docutils literal notranslate"><span class="pre">latent_dim</span></code> and the <code class="docutils literal notranslate"><span class="pre">upsampler</span></code>. of the <code class="docutils literal notranslate"><span class="pre">autoencoder</span></code> model.
The output of the <code class="docutils literal notranslate"><span class="pre">upsampler</span></code> should be the same size as the <code class="docutils literal notranslate"><span class="pre">latent_dim</span></code>.
If we modify both of these to be mismatched, let‚Äôs see what happens.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">layer_mods</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;denoising_autoencoder_subspace_method&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;autoencoder.latent_dim&quot;</span><span class="p">:</span> <span class="mi">450</span><span class="p">,</span>
        <span class="s2">&quot;autoencoder.upsampler&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">300</span><span class="p">),</span>  <span class="c1"># this should be 450 to match the latent_dim</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
        <span class="p">)</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="c1"># get the data and train the subspace models</span>
<span class="n">datamodule</span> <span class="o">=</span> <span class="n">get_data_module</span><span class="p">(</span><span class="n">DAETabImgMaps</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">layer_mods</span><span class="o">=</span><span class="n">layer_mods</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Changed latent_dim in denoising_autoencoder_subspace_method
Changed upsampler in denoising_autoencoder_subspace_method
Reset fused layers in denoising_autoencoder_subspace_method

Training: |          | 0/? [00:00&lt;?, ?it/s]
Training:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 322.39it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 308.86it/s]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 360.89it/s]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 350.87it/s]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 379.03it/s]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 373.24it/s]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 392.85it/s]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 388.42it/s]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 395.47it/s]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 391.39it/s]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 404.75it/s]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 401.55it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 415.33it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 411.67it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 327.67it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 324.49it/s]
Epoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 1:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 391.11it/s]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 373.13it/s]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 411.37it/s]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 402.99it/s]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 434.60it/s]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 429.11it/s]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 440.14it/s]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 433.65it/s]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 439.53it/s]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 435.20it/s]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 432.40it/s]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 427.54it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 433.65it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 430.66it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 357.42it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 354.09it/s]
Epoch 1:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 2:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 409.68it/s]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 391.55it/s]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 417.36it/s]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 405.68it/s]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 414.95it/s]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 408.39it/s]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 421.77it/s]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 415.42it/s]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 421.91it/s]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 417.75it/s]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 428.63it/s]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 425.21it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 438.32it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 435.06it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 350.05it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 346.69it/s]
Epoch 2:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 3:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 437.45it/s]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 418.05it/s]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 459.35it/s]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 445.92it/s]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 456.70it/s]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 449.42it/s]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 453.30it/s]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 448.58it/s]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 455.95it/s]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 450.40it/s]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 448.09it/s]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 444.51it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 453.49it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 449.87it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 358.83it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 355.45it/s]
Epoch 3:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 4:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 442.25it/s]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:00, 422.13it/s]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 447.34it/s]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:00, 435.84it/s]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 448.97it/s]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:00, 440.33it/s]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 438.16it/s]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:00&lt;00:00, 433.27it/s]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 444.96it/s]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:00&lt;00:00, 440.57it/s]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 444.19it/s]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:00&lt;00:00, 440.27it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 447.83it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 444.73it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 368.95it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 365.33it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00&lt;00:00, 308.57it/s]

Training: |          | 0/? [00:00&lt;?, ?it/s]
Training:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:02,  2.88it/s]
Epoch 0:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:02,  2.88it/s]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  2.97it/s]
Epoch 0:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  2.97it/s]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.02it/s]
Epoch 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.02it/s]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.02it/s]
Epoch 0:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.02it/s]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.02it/s]
Epoch 0:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.02it/s]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.03it/s]
Epoch 0:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.03it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.37it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.37it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.10it/s]
Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.10it/s]
Epoch 0:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 1:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.05it/s]
Epoch 1:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.05it/s]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.05it/s]
Epoch 1:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.05it/s]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.06it/s]
Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.05it/s]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.05it/s]
Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.05it/s]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.06it/s]
Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.06it/s]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.05it/s]
Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.05it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.39it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.39it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.12it/s]
Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.12it/s]
Epoch 1:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 2:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.06it/s]
Epoch 2:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.06it/s]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.07it/s]
Epoch 2:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.07it/s]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.07it/s]
Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.07it/s]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.07it/s]
Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.07it/s]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.07it/s]
Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.07it/s]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.07it/s]
Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.07it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.41it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.41it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.13it/s]
Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.13it/s]
Epoch 2:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 3:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.07it/s]
Epoch 3:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.06it/s]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.05it/s]
Epoch 3:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.05it/s]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.06it/s]
Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.06it/s]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.06it/s]
Epoch 3:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.06it/s]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.06it/s]
Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.06it/s]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.06it/s]
Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.06it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.40it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.40it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.12it/s]
Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.12it/s]
Epoch 3:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 4:   0%|          | 0/7 [00:00&lt;?, ?it/s]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.02it/s]
Epoch 4:  14%|‚ñà‚ñç        | 1/7 [00:00&lt;00:01,  3.02it/s]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.05it/s]
Epoch 4:  29%|‚ñà‚ñà‚ñä       | 2/7 [00:00&lt;00:01,  3.04it/s]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.04it/s]
Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3/7 [00:00&lt;00:01,  3.04it/s]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.04it/s]
Epoch 4:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 4/7 [00:01&lt;00:00,  3.04it/s]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.05it/s]
Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 5/7 [00:01&lt;00:00,  3.05it/s]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.05it/s]
Epoch 4:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 6/7 [00:01&lt;00:00,  3.05it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.40it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.40it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.12it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.12it/s]
Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:02&lt;00:00,  3.11it/s]
</pre></div>
</div>
<p><strong>Wow it still works!</strong>
Let‚Äôs have a look at what the model structure looks like to see what changes have been made to keep the model valid.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">datamodule</span><span class="o">.</span><span class="n">subspace_method_train</span><span class="o">.</span><span class="n">autoencoder</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>DenoisingAutoencoder(
  (upsampler): Sequential(
    (0): Linear(in_features=10, out_features=100, bias=True)
    (1): ReLU()
    (2): Linear(in_features=100, out_features=200, bias=True)
    (3): ReLU()
    (4): Linear(in_features=200, out_features=450, bias=True)
    (5): ReLU()
  )
  (downsampler): Sequential(
    (0): Linear(in_features=450, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): ReLU()
    (4): Linear(in_features=128, out_features=10, bias=True)
    (5): ReLU()
  )
  (loss): MSELoss()
)
</pre></div>
</div>
<p>As you can see, a few corrections have been made to the modifications:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">upsampler</span></code> has been modified to have the correct number of nodes in the final layer to match the <code class="docutils literal notranslate"><span class="pre">latent_dim</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">downsample</span></code> (which we didn‚Äôt specify a modification for) now has the correct number of nodes in the first layer to match the <code class="docutils literal notranslate"><span class="pre">latent_dim</span></code>.</p></li>
</ul>
<p>In general, there are checks in the fusion models to make sure that the modifications are valid.
If the input number of nodes to a modification is not correct, then the model will automatically calculate the correct number of nodes and correct the modification.</p>
<p>This is the case for quite a few modifications, but potentially not all of them so please be careful!
Make sure to print out the model structure to check that the modifications have been made correctly and see what changes have been made to keep the model valid.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># removing checkpoints</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;checkpoint_dir&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;/DAETabImgMaps_epoch=04.ckpt&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;checkpoint_dir&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;/subspace_DAETabImgMaps_DenoisingAutoencoder.ckpt&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;checkpoint_dir&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;/subspace_DAETabImgMaps_ImgUnimodalDAE.ckpt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> (0 minutes 28.091 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-customising-behaviour-plot-modify-layer-sizes-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/8a414ac5dfcbc0c796d0c3a412b39cce/plot_modify_layer_sizes.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_modify_layer_sizes.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/3660c71b15ecc4dbb86ab88828110332/plot_modify_layer_sizes.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_modify_layer_sizes.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="how_to_use_logging.html" class="btn btn-neutral float-left" title="How to use Weights and Biases Logging with Fusilli" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../contributing_examples/index.html" class="btn btn-neutral float-right" title="Adding a new model" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Florence J Townend.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>