{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Operation/attention/tensor fusion template\n\nThis is a template for creating your own fusion model: operation-based, attention-based, or tensor-based.\nIf you want to implement a graph-based or subspace-based fusion model, please refer to the other templates. They require additional functions to be implemented.\n\nThere are two ways to create your own fusion model:\n\n1. You can use the preset layers in the :class:`~fusionlibrary.fusion_models.base_pl_model.ParentFusionModel` class. This is the easiest way to create your own fusion model. You can see an example of this in the :class:`~fusionlibrary.fusion_models.concat_tabular_data.ConcatTabularData` class.\n2. You can create your own layers. This is the most flexible way to create your own fusion model.\n\nThe most important thing to remember is to output the final prediction as a list. This is because in subspace methods, the output is the label output and a reconstruction. This project's architecture is designed to be flexible enough to handle subspace methods too, hence the need for a list.\n\nHave fun creating your own fusion model!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\nimport torch\n\n# importing the parent fusion model class\nfrom fusionlibrary.fusion_models.base_pl_model import ParentFusionModel\n\n\nclass TemplateFusionModel(ParentFusionModel, nn.Module):\n    \"\"\"\n    Do you want to create your own multi-modal fusion model? This is the template for you!\n\n    Attributes\n    ----------\n    method_name : str\n        Name of the method.\n    modality_type : str\n        Type of modality.\n    fusion_type : str\n        Type of fusion.\n    pred_type : str\n        Type of prediction to be performed.\n    mod1_layers : dict\n        Dictionary containing the layers of the first modality.\n    mod2_layers : dict\n        Dictionary containing the layers of the second modality.\n    fused_layers : nn.Sequential\n        Sequential layer containing the fused layers.\n    final_prediction : nn.Sequential\n        Sequential layer containing the final prediction layers. The final prediction layers\n        take in the number of features of the fused layers as input.\n\n    Methods\n    -------\n    forward(x)\n        Forward pass of the model.\n\n    \"\"\"\n\n    method_name = \"Template fusion model\"\n    modality_type = \"both_tab\"  # or \"tabular1\", \"tabular2\", \"both_tab\", \"tab_img\"\n    fusion_type = \"attention\"  # or \"operation\", \"tensor\", \"graph\", \"subspace\"\n\n    def __init__(self, pred_type, data_dims, params):\n        ParentFusionModel.__init__(self, pred_type, data_dims, params)\n        self.pred_type = pred_type\n\n        ################################\n        # SETTING THE UNI-MODAL LAYERS #\n        ################################\n        # You can either set the layers to be consistent with the rest of the library\n        # or you can set your own layers.\n\n        # USING PARENTFUSIONMODEL PRESET LAYERS\n        self.set_mod1_layers()  # set the layers for the first tabular modality\n        self.set_mod2_layers()  # set the layers for the second tabular modality\n        self.set_img_layers()  # set the layers for the image modality (if using)\n\n        ################################\n        #   SETTING THE FUSED LAYERS   #\n        ################################\n\n        # Setting a fused dimension: how many features are there after the fusion?\n        # e.g. concatenating two tabular modalities would be the sum of the number of features\n        self.fused_dim = self.mod1_dim + self.mod2_dim\n\n        # Setting the fused layers: how do you want to fuse the modalities?\n        # Again, you can either set the layers to be consistent with the rest of the library\n        # or you can set your own layers.\n\n        # USING PARENTFUSIONMODEL PRESET LAYERS\n        self.set_fused_layers(self.fused_dim)\n\n        #################################\n        # SETTING THE FINAL PRED LAYERS #\n        #################################\n\n        # Setting the final prediction layers: how do you want to make the final prediction?\n        self.set_final_pred_layers(input_dim=self.fused_dim)\n        # Default input dim to final_pred_layers is 64, but you can change this in the function call.\n\n    def forward(self, x):\n        \"\"\"\n        Forward pass of the model. This is an example of a concatenation of feature maps!\n        Feel free to change this to suit your model - get creative!!\n\n        Parameters\n        ----------\n        x : list\n            List containing the input data.\n\n        Returns\n        -------\n        list\n            List containing the output of the model.\n        \"\"\"\n\n        x_tab1 = x[0]  # tabular1 data\n        x_tab2 = x[1]  # tabular2 data\n\n        # pass the data through the modality layers\n        for i, (k, layer) in enumerate(self.mod1_layers.items()):\n            x_tab1 = layer(x_tab1)\n            x_tab2 = self.mod2_layers[k](x_tab2)\n\n        # pass the data through the fused layers\n        out_fuse = torch.cat((x_tab1, x_tab2), dim=-1)\n        out_fuse = self.fused_layers(out_fuse)\n\n        # pass the data through the final prediction layers\n        out = self.final_prediction(out_fuse)\n\n        # You have to return the output of the model as a list.\n        # This is because in subspace methods, the output is the label output and a reconstruction.\n        # This project's architecture is designed to be flexible enough to handle subspace methods too, hence the list.\n\n        return [\n            out,\n        ]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}